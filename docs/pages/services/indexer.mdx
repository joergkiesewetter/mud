import { Callout } from "nextra/components";
import { CollapseCode } from "../../components/CollapseCode";

# Indexer

There are two ways for an offchain client to get MUD information directly from an Ethereum node:

- Call `view` functions, which only works if you already know the key to search for, and requires a call to the node for every record.
- Get the history from events, which requires running event queries going all the way back to when the `World` was first created.

Both solutions are slow and require a lot of processing from the node.

Instead, you can use the MUD Indexer, an offchain server that collects all the MUD events and provides them to clients when requested.
Then the client can calculate the current state of the MUD tables, and it just needs to listen for ongoing updates, a much cheaper process.

## Installation

These environment variables need to be provided to the indexer to work:

| Type                      | Variable        | Meaning                                                                                                  | Sample value (using `anvil` running on the host)          |
| ------------------------- | --------------- | -------------------------------------------------------------------------------------------------------- | --------------------------------------------------------- |
| Needed                    | RPC_HTTP_URL    | The URL to access the blockchain using HTTP                                                              | http://host.docker.internal:8545 (when running in Docker) |
| Optional                  | RPC_WS_URL      | The URL to access the blockchain using WebSocket                                                         |
| Optional                  | START_BLOCK     | The block to start indexing from. The block in which the `World` contract was deployed is a good choice. | 1                                                         |
| Optional                  | DEBUG=mud:\*    | Turn on debugging                                                                                        |                                                           |
| Optional                  | STORE_ADDRESS   | Only index tables from this `World`                                                                      |
| Optional, only for SQLite | SQLITE_FILENAME | Name of database                                                                                         | `indexer.db`                                              |
| Required for PostgreSQL   | DATABASE_URL    | URL for the database, of the form `postgres://<host>/<database>`                                         |

### Schemaful indexing to SQLite via npx

To run the indexer directly on your computer using SQLite:

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Set `RPC_HTTP_URL`.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   ```

1. Run the indexer.
   If necessary, install it first.

   ```bash copy
   npx -y -p @latticexyz/store-indexer sqlite-indexer
   ```

**Note:** The `indexer.db` is persistent if you stop and restart the indexer.
If that is not the desired behavior (for example, because you restarted the blockchain itself), delete it before starting the indexer.

### Schemaless indexing to PostgreSQL via npx

The schemaless indexer stores MUD table records into a single monolithic table.
This allows it to index the data of all tables of all MUD Worlds on a chain efficiently, but querying for data is limited to filters on `address`, `tableId`, and the record's key.
Since the record's `data` is stored as encoded bytes blob, it's harder to query based on it in SQL.
The main purpose of this variant of the indexer is to efficiently hydrate a MUD client, which decodes the data.

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Set the environment variables.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   export DATABASE_URL=postgres://127.0.0.1/postgres
   ```

1. Run the indexer.
   Install it first if necessary.

   ```bash copy
   npx -y -p @latticexyz/store-indexer postgres-indexer
   ```

1. Open a separate command line.
   In it, specify the database and run the indexer frontend, which is responsible for serving the data to the client.

   ```bash copy
   export DATABASE_URL=postgres://127.0.0.1/postgres
   npx -y -p @latticexyz/store-indexer postgres-frontend
   ```

### Schemaful indexing with PostgreSQL via npx

The schemaful indexer dynamically creates a PostgreSQL table every time it encounters a new MUD table.
It then decodes the MUD events and stores it in the PostgreSQL table with a matching schema.
This approach doesn't scale well to all tables of a chain, but it is a convenient way to index the tables of a particular MUD World and have access to powerful SQL queries on its data.

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Set the environment variables and start the indexer, installing it if necessary.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   export DATABASE_URL=postgres://127.0.0.1/postgres
   npx -y -p @latticexyz/store-indexer postgres-decoded-indexer
   ```

1. To verify the installation, run `psql` and then:

   - List the schemas.

     ```sql copy
     \dn
     ```

     Result:

     ```
                       List of schemas
                       Name                    | Owner
     --------------------------------------------+-------
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | qbzzt
     mud                                        | qbzzt
     ```

   - Connect to the schema for your world.

     ```sql copy
     SET search_path TO "0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1";
     ```

   - Get the list of tables.

     ```sql copy
     \dt
     ```

     Result (When using the React template):

     ```
                                      List of relations
                       Schema                   |           Name            | Type  | Owner
     --------------------------------------------+---------------------------+-------+-------
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | store__resource_ids       | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | store__store_hooks        | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | store__tables             | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | tasks                     | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__balances           | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__function_selector  | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__function_signatur  | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__init_module_addres | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__installed_modules  | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__namespace_delegat  | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__namespace_owner    | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__resource_access    | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__system_hooks       | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__system_registry    | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__systems            | table | qbzzt
     0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1 | world__user_delegation_co | table | qbzzt
     (16 rows)
     ```

   - Read the actual data.

     ```sql copy
     SELECT * FROM tasks;
     ```

     Result:

     ```
                                     id                                 | created_at | completed_at |    description     |                            __key_bytes                             | __last_updated_block_number
     -------------------------------------------------------------------+------------+--------------+--------------------+--------------------------------------------------------------------+-----------------------------
     \x3100000000000000000000000000000000000000000000000000000000000000 | 1712714176 |            0 | Walk the dog       | \x3100000000000000000000000000000000000000000000000000000000000000 |                          10
     \x5e9c11602057fbf149cca23095b1863f7ffa8d0d0bd9434005a344ad612488a7 | 1712714178 |            0 | Take out the trash | \x5e9c11602057fbf149cca23095b1863f7ffa8d0d0bd9434005a344ad612488a7 |                          10
     \x0c9151148be227a42be8d3e3e7e61da28a532f2340b0ad9ca8bc747703ec2417 | 1712714178 |   1712714178 | Do the dishes      | \x0c9151148be227a42be8d3e3e7e61da28a532f2340b0ad9ca8bc747703ec2417 |                          10
     (3 rows)
     ```

### Docker

The indexer Docker image is available [on github](https://github.com/latticexyz/mud/pkgs/container/store-indexer).

There are several ways to provide the environment variables to `docker run`:

- On the command line you can specify `-e <variable>=<value>`.
  You specify this after the `docker run`, but before the name of the image.
- You can also write all the environment variables in a file and specify it using `--env-file`.
  You specify this after the `docker run`, but before the name of the image.
- Both [Docker Compose](https://docs.docker.com/compose/) and [Kubernetes](https://kubernetes.io/) have their own mechanisms for starting docker containers with environment variables.

The easiest way to test the indexer is to [run the template as a world](/templates/typescript/getting-started) in a separate command-line window.

#### SQLite

The command to start the indexer in SQLite mode is `pnpm start:sqlite`.
To index an `anvil` instance running to the host you can use this command.

```sh copy
docker run \
  --platform linux/amd64 \
  -e RPC_HTTP_URL=http://host.docker.internal:8545 \
  -p 3001:3001  \
  ghcr.io/latticexyz/store-indexer:latest  \
  pnpm start:sqlite
```

However, this creates a docker container with a state, the SQLite database file.
If we start a new container with the same image and parameters, it is going to have to go back to the start of the blockchain, which depending on how long the blockchain has been in use may be a problem.
We can solve this with [volumes](https://docs.docker.com/storage/volumes/):

1. Create a docker volume for the SQLite database file.

   ```sh copy
   docker volume create sqlite-db-file
   ```

1. Run the indexer container using the volume.

   ```sh copy
   docker run \
      --platform linux/amd64 \
      -e RPC_HTTP_URL=http://host.docker.internal:8545 \
      -e SQLITE_FILENAME=/dbase/indexer.db \
      -v sqlite-db-file:/dbase \
      -p 3001:3001  \
      ghcr.io/latticexyz/store-indexer:latest  \
      pnpm start:sqlite
   ```

1. You can stop the docker container and restart it, or start a separate container using the same database.

1. When you are done, you have to delete the docker containers that used it before you can delete the volume.
   You can use these commands:

   ```sh copy
   docker rm `docker ps -a --filter volume=sqlite-db-file -q`
   docker volume rm sqlite-db-file
   ```

   **Note:** You should do this every time you restart the blockchain.
   Otherwise your index will include data from multiple blockchains, and make no sense.

#### Schemaless indexing with PostgreSQL via Docker

The command to start the indexer in schemaless PostgreSQL mode is `pnpm start:postgres`.
This command starts both the indexer and query frontends.

1. The docker instance identifies itself to PostgreSQL as `root`.
   To give this user permissions on the database, enter `psql` and run this command.

   ```sql copy
   CREATE ROLE root SUPERUSER LOGIN;
   ```

   **Note:** This is assuming a database that is isolated from the internet and only used by trusted entities.
   In a production system you will use at least a password as authentication, and limit the user's authority.

1. Start the docker container.
   For example, to index an `anvil` instance running to the host to the database `postgres` on the host, use.

   ```sh copy
   docker run \
     --platform linux/amd64 \
     -e RPC_HTTP_URL=http://host.docker.internal:8545 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p 3001:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     pnpm start:postgres
   ```

   If you want to create additional query frontends (for reliability and load balancing), use these commands:

   ```sh copy
   HOST_PORT=3002
   docker run \
     --platform linux/amd64 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p $HOST_PORT:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     node dist/bin/postgres-frontend.js
   ```

#### Schemaful indexing with PostgreSQL via Docker

The command to start the indexer in schemaful PostgreSQL mode is `pnpm start:postgres-decoded`.
This command starts both the indexer and the query frontend.

1. The docker instance identifies itself to PostgreSQL as `root`.
   To give this user permissions on the database, enter `psql` and run this command.

   ```sql copy
   CREATE ROLE root SUPERUSER LOGIN;
   ```

   **Note:** This is assuming a database that is isolated from the internet and only used by trusted entities.
   In a production system you will use at least a password as authentication, and limit the user's authority.

1. Start the docker container.
   For example, to index an `anvil` instance running to the host to the database `postgres` on the host, use.

   ```sh copy
   docker run \
     --platform linux/amd64 \
     -e RPC_HTTP_URL=http://host.docker.internal:8545 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p 3001:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     pnpm start:postgres-decoded
   ```

### Verification

If you use either SQLite or PostgreSQL with the query frontend (using PostgreSQL only as storage), you can run this command to test the indexer.

```sh copy
curl 'http://localhost:3001/api/logs?batch=1&input=%7B%0A%20%20%20%20%20%20%22chainId%22%3A%2031337%2C%0A%20%20%20%20%20%20%22address%22%3A%20%220xd6c8022f1af8e9d7c3825557a1374ee518c65a4e%22%0A%7D' | jq | more
```

The result should be nicely formatted (and long) JSON output with all the data stored in the `World`.

<details>

<summary>Where does this URL come from?</summary>

The URL has these parameters:

| Parameter | Value                 | Explanation                                 |
| --------- | --------------------- | ------------------------------------------- |
| Server    | http://localhost:3001 | By default the indexer listens on port 3001 |
| Path      | /api/logs             | Return all events for the requested `World` |
| `batch`   | `1`                   | A required field                            |
| `input`   | `%7B%0A ... %0A%7D`   | See below                                   |

The input is the JSON filter that tells the server what we need.
It is [URL encoded](https://en.wikipedia.org/wiki/Percent-encoding), you can decode it [using an online calculator](https://www.urldecoder.org/).

```json
{
  "chainId": 31337,
  "address": "0xd6c8022f1af8e9d7c3825557a1374ee518c65a4e"
}
```

Meaning that we want the events in the `World` at address `0xd6c8022f1af8e9d7c3825557a1374ee518c65a4e`, on the chain with chain ID `31337`.

</details>

{ /\*

## Using the indexer

The source code of a MUD client has a call either to [`syncToRecs`](https://github.com/latticexyz/mud/blob/main/packages/store-sync/src/recs/syncToRecs.ts#L21-L82) or to [`syncToZustand`](https://github.com/latticexyz/mud/blob/main/packages/store-sync/src/zustand/syncToZustand.ts#L33-L74), typically in [`setupNetwork.ts`](https://github.com/latticexyz/mud/blob/main/templates/react/packages/client/src/mud/setupNetwork.ts#L74-L79).
This call initializes the synchronization between the data source (RPC or indexer) and the client's copy.

To use the indexer, specify an `indexerUrl` parameter with the URL.

<CollapseCode>

```ts {7}
const { components, latestBlock$, storedBlockLogs$, waitForTransaction } = await syncToRecs({
  world,
  config: mudConfig,
  address: networkConfig.worldAddress as Hex,
  publicClient,
  startBlock: BigInt(networkConfig.initialBlockNumber),
  indexerUrl: "http://127.0.0.1:3001",
});
```

</CollapseCode>

If the client does not need all the information stored in the `World`, you can [filter the synchronization](/guides/hello-world/filter-sync) to save on resources.

### Clearing the information

If you restart the blockchain, you need to clear all the information stored by the indexer otherwise you'll have an inconsistent state.

- If you are using SQLite, remove `indexer.db`.

- If you are using schemaless PostgreSQL, you just need to remove the `mud` schema:

  ```sql copy
  DROP SCHEMA "mud" CASCADE;
  ```

- If you are using schemaful PostgreSQL, you need to also remove the schemas for the `World`s indexed.

  1. Get the list of `World`s using this command:

     ```sql copy
     SELECT DISTINCT address FROM mud.records;
     ```

  1. Delete those schemas.
     For example, if you use one of the TypeScript templates, run this command:

     ```sql copy
     DROP SCHEMA "0xc14fbdb7808d9e2a37c1a45b635c8c3ff64a1cc1" CASCADE;
     ```

  1. Drop the `mud` schema.

     ```sql copy
     DROP SCHEMA mud CASCADE;
     ```

## Usage examples

\*/ }
